{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as album\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "#from dataloaders.datasets import Pathology\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# sdm\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "from skimage import segmentation as skimage_seg\n",
    "from skimage import morphology\n",
    "\n",
    "# test loader\n",
    "import itertools\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "import math\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data as training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "ENCODER = 'timm-resnest50d' #'timm-resnest50d' 'densenet201' 'resnet34'\n",
    "ENCODER_WEIGHTS = None\n",
    "CLASSES = class_names\n",
    "ACTIVATION ='softmax2d'  #'identity' # 'softmax2d'\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.cuda.set_device(DEVICE)\n",
    "print(DEVICE)\n",
    "#ACTIVATION = 'sigmoid'could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation= ACTIVATION,\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_iou_score_list = []\n",
    "micro_f1_score_list = []\n",
    "micro_accuracy_list = []\n",
    "micro_recall_list = []\n",
    "micro_precision_list = []\n",
    "micro_sensitivity_list = []\n",
    "micro_specificity_list = []\n",
    "\n",
    "best_model=model\n",
    "n=0\n",
    "best_model.load_state_dict(torch.load('./model/resnest_sdm.pth', map_location=DEVICE))\n",
    "with torch.no_grad(): \n",
    "    best_model.eval()\n",
    "    total=len(test_loader)\n",
    "    for i, data in enumerate(itertools.islice(test_loader, total-1)):\n",
    "\n",
    "        inputs = data['img']['image']\n",
    "\n",
    "        labels = data['label'] \n",
    "\n",
    "        inputs, labels = inputs.float().to(DEVICE), labels.float().to(device=DEVICE, dtype=torch.int64) \n",
    "        preds = best_model(inputs)    \n",
    "        output = F.softmax(preds, dim=1)\n",
    " \n",
    "        target = labels\n",
    "\n",
    "\n",
    "        _, output = torch.max(output, 1)\n",
    "\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(output, target, mode='multilabel', threshold=0.5)        \n",
    "        \n",
    "        micro_iou_score = round(smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_f1_score = round(smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_accuracy = round(smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"micro\").item(),3)\n",
    "        micro_recall = round(smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_precision = round(smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_sensitivity = round(smp.metrics.sensitivity(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_specificity = round(smp.metrics.specificity(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "\n",
    "        micro_iou_score_list.append(micro_iou_score)\n",
    "        micro_f1_score_list.append(micro_f1_score)\n",
    "        micro_accuracy_list.append(micro_accuracy)\n",
    "        micro_recall_list.append(micro_recall)\n",
    "        micro_precision_list.append(micro_precision)\n",
    "        micro_sensitivity_list.append(micro_sensitivity)\n",
    "        micro_specificity_list.append(micro_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.title('micro_iou_score')\n",
    "plt.plot(micro_iou_score_list,'r-',label='IoU_score')\n",
    "plt.grid(color = 'gray', linestyle = ':', linewidth = 0.5)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.title('micro_f1_score')\n",
    "plt.plot(micro_f1_score_list,'b-',label='f1_score')\n",
    "plt.grid(color = 'gray', linestyle = ':', linewidth = 0.5)\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.title('micro_accuracy')\n",
    "plt.plot(micro_accuracy_list,'y-',label='accuracy')\n",
    "plt.grid(color = 'gray', linestyle = ':', linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_average(metrics_list):\n",
    "    metric_avg = sum([x for x in metrics_list if isinstance(x, (int, float)) and not math.isnan(x)])/len(metrics_list)\n",
    "    return round(metric_avg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"micro_iou_score: \",metrics_average(micro_iou_score_list))\n",
    "print(\"micro_f1_score_score: \",metrics_average(micro_f1_score_list))\n",
    "print(\"micro_accuracy_score: \",metrics_average(micro_accuracy_list))\n",
    "print(\"micro_recall_score: \",metrics_average(micro_recall_list))\n",
    "print(\"micro_precision_score: \",metrics_average(micro_precision_list))\n",
    "print(\"micro_sensitivity_score: \",metrics_average(micro_sensitivity_list))\n",
    "print(\"micro_specificity_score: \",metrics_average(micro_specificity_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize at once(input, target, prediction, sdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_classes = ['background', 'tumor', 'stroma', 'dcis']\n",
    "sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(sem_classes)} \n",
    "tumor_category = sem_class_to_idx[\"tumor\"]\n",
    "stroma_category = sem_class_to_idx[\"stroma\"]\n",
    "dcis_category = sem_class_to_idx[\"dcis\"]\n",
    "\n",
    "best_model = model\n",
    "best_model.load_state_dict(torch.load('./[BCSS]segmentation_model/sdm_semi_unet_resnest50.pth', map_location=DEVICE))\n",
    "def visualize_one_sample(test_x_data, test_y_data, model):\n",
    "\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        X = test_x_data.float().to(DEVICE)\n",
    "        Y = test_y_data\n",
    "        prediction = model(X)  # ì˜ˆ: output shape=(B, num_classes, H, W)\n",
    "        #sdm\n",
    "        prediction = F.softmax(prediction, dim=1)\n",
    "        \n",
    "      \n",
    "        _, pred_mask = torch.max(prediction, 1)  # shape=(B, H, W)\n",
    "        pred_mask = pred_mask[0].cpu().numpy()\n",
    "        target_mask = Y[0].cpu().numpy().squeeze()\n",
    "\n",
    "       \n",
    "        input_img = X[0].cpu().numpy()\n",
    "        if input_img.ndim == 3 and input_img.shape[0] in [1, 3]:\n",
    "            if input_img.shape[0] == 1:\n",
    "                input_img = input_img.squeeze(0)\n",
    "                cmap_input = 'viridis' \n",
    "            else:\n",
    "                input_img = np.transpose(input_img, (1, 2, 0))\n",
    "                cmap_input = None \n",
    "        else:\n",
    "            cmap_input = 'viridis'\n",
    "        \n",
    "      \n",
    "        # binary_mask = ((pred_mask == tumor_category) | (pred_mask == stroma_category)).astype(np.uint8)\n",
    "        binary_mask = np.where(np.isin(pred_mask, [0, 1, 2]), pred_mask, 0)\n",
    "\n",
    "        # sdm = compute_sdm(pred_mask).squeeze()\n",
    "        # sdm = torch.from_numpy(sdm).float()\n",
    "        \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].imshow(input_img, cmap=cmap_input)\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[0].axis(\"off\")\n",
    "    \n",
    "    \n",
    "    axs[1].imshow(target_mask, cmap='viridis') \n",
    "    axs[1].set_title(\"Target\")\n",
    "    axs[1].axis(\"off\")\n",
    "    \n",
    "\n",
    "    axs[2].imshow(pred_mask, cmap='viridis')\n",
    "    axs[2].set_title(\"Prediction\")\n",
    "    axs[2].axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "test_x_data_path = ''\n",
    "test_y_data_path = ''\n",
    "\n",
    "test_x_data = sorted(os.listdir(test_x_data_path))\n",
    "test_y_data = sorted(os.listdir(test_y_data_path))\n",
    "\n",
    "for i in range(50, 52):\n",
    "\n",
    "   xname = test_x_data[i]\n",
    "   yname = test_y_data[i]\n",
    "\n",
    "   x_path = os.path.join(test_x_data_path, xname)\n",
    "   y_path = os.path.join(test_y_data_path, yname)\n",
    "    \n",
    "    \n",
    "   x = cv2.imread(x_path)\n",
    "   x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "   X = torch.Tensor(x)\n",
    "   X = X /255\n",
    "    \n",
    "\n",
    "   y = cv2.imread(y_path)    \n",
    "   y = cv2.cvtColor(y, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "   Y = torch.Tensor(y)\n",
    "\n",
    "   print(\"x file : \",xname)\n",
    "   print(\"y file : \",yname)\n",
    "\n",
    "    \n",
    "   X = np.transpose(X, (2, 0, 1))\n",
    "   Y = np.transpose(Y, (2, 0, 1))\n",
    "    \n",
    "   X.unsqueeze_(0)\n",
    "   Y.unsqueeze_(0)\n",
    "\n",
    "   visualize_one_sample(X, Y, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "macs, params = get_model_complexity_info(model, input_res=(3, 256, 256), as_strings=True)\n",
    "\n",
    "print(f'FLOPs: {macs}, Params: {params}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
