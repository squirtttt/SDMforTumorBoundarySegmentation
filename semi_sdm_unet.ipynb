{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdfee7e2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129070b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1\n",
    "import os\n",
    "import sys\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as album\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "#from dataloaders.datasets import Pathology\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# sdm\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "from skimage import segmentation as skimage_seg\n",
    "from skimage import morphology\n",
    "\n",
    "# test loader\n",
    "import itertools\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "DATA_DIR = './PathologyDataset/labelled/'\n",
    "x_train_dir = os.path.join(DATA_DIR, 'train/png')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'train/png_label')\n",
    "train_dir = os.path.join(DATA_DIR, 'train/npy')\n",
    "\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test/png')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test/png_label')\n",
    "test_dir = os.path.join(DATA_DIR, 'test/npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no~\n",
    "'''\n",
    "import shutil\n",
    "print(x_train_dir+\"/\")\n",
    "print(train_dir+\"/\")\n",
    "\n",
    "def filename_without_ext(folder):\n",
    "    filenames = os.listdir(folder)\n",
    "    filename_without_ext = {os.path.splitext(filename)[0] for filename in filenames}\n",
    "    return filename_without_ext\n",
    "\n",
    "file_npy = filename_without_ext(train_dir)\n",
    "file_png = filename_without_ext(x_train_dir)\n",
    "\n",
    "print(len(file_npy))\n",
    "print(len(file_png))\n",
    "\n",
    "difference = file_png - file_npy\n",
    "d_dir = os.path.join(DATA_DIR, \"train/no_npy\")\n",
    "print(len(difference))\n",
    "for files in difference:\n",
    "    s_path = os.path.join(x_train_dir, files+\".png\")\n",
    "    d_path = os.path.join(d_dir, files+\".png\")\n",
    "    shutil.move(s_path, d_path)\n",
    "    print(f\"{files}.png has been moved to {d_path}\")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e6818d3",
   "metadata": {},
   "source": [
    "### data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"\n",
    "    Plot images in one row\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n_images, idx + 1)\n",
    "        plt.xticks([]); \n",
    "        plt.yticks([])\n",
    "        # get title from the parameter names\n",
    "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# Perform one hot encoding on label\n",
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "\n",
    "    return semantic_map\n",
    "    \n",
    "# Perform reverse one-hot-encoding on labels / preds\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis = -1)\n",
    "    return x\n",
    "\n",
    "# Perform colour coding on the reverse-one-hot outputs\n",
    "def colour_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ef28dd9",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# Useful to shortlist specific classes in datasets with large number of classes\n",
    "class_names = ['background', 'benign', 'malignant']\n",
    "select_classes = ['background', 'benign', 'malignant']\n",
    "\n",
    "background=[[0, 0, 0],]\n",
    "\n",
    "# Get RGB values of required classes\n",
    "class_rgb_values = [[0, 0, 0], [255, 0, 0], [0, 255, 0]]\n",
    "\n",
    "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
    "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
    "\n",
    "print('Selected classes and their corresponding RGB values in labels:')\n",
    "print('Class Names: ', class_names)\n",
    "print('Class RGB values: ', class_rgb_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e999a997",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def get_training_augmentation():\n",
    "    train_transform = [    \n",
    "        #album.RandomCrop(height=256, width=256, always_apply=True),\n",
    "        album.OneOf(\n",
    "            [\n",
    "                album.HorizontalFlip(p=1),\n",
    "                album.VerticalFlip(p=1),\n",
    "                album.RandomRotate90(p=1),\n",
    "            ],\n",
    "            p=1,\n",
    "        ),\n",
    "    ]\n",
    "    return album.Compose(train_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn=None):\n",
    "    _transform = []\n",
    "    if preprocessing_fn:\n",
    "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
    "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
    "        \n",
    "    return album.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5612797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from utils.mypath import Path\n",
    "\n",
    "class PathologyDataset(Dataset): #class PathologyDataset(Dataset):\n",
    "    def __init__(self, args, augmentation, split:str):\n",
    "\n",
    "        self.augmentation = augmentation\n",
    "        self.args = args\n",
    "        self.data_dir = os.path.join(Path.pathology_root_dir(), 'labelled', split, 'png')\n",
    "        self.imgs = [os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir)]\n",
    "        #png images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        # return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _img = cv2.cvtColor(cv2.imread(self.imgs[index]), cv2.COLOR_BGR2RGB)\n",
    "        mask_pth = self.imgs[index].replace(\"png\", \"npy\")\n",
    "        _label = np.load(mask_pth, allow_pickle=True).item().get('label')\n",
    "        #print(\"~!~!~!~!~!~!~\")\n",
    "        # apply augmentations\n",
    "        if self.augmentation != None:\n",
    "            sample = self.augmentation(image=_img, mask=_label)\n",
    "            _img, _label = sample['image'], sample['mask']\n",
    "            #print(\"augmentation !!!\")\n",
    "\n",
    "        #_img = read_image(self.imgs[index])\n",
    "        _img = _img / 255\n",
    "        transform = A.Compose([ToTensorV2()])\n",
    "        _img = transform(image=_img)\n",
    "        #_label_pth = self.imgs[index].replace(\"png\", \"npy\")\n",
    "        #_label = np.load(_label_pth, allow_pickle=True).item().get('label')\n",
    "        # _label[_label>0] = 1\n",
    "        _label = torch.as_tensor(_label).long()\n",
    "\n",
    "        sample = {\n",
    "            'img':_img,\n",
    "            'label':_label\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518f4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#7\n",
    "train_augmented_dataset = PathologyDataset([], get_training_augmentation(), \"train\") #Pathology.PathologyDataset()\n",
    "\n",
    "print(len(train_augmented_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):   \n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6a960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#8\n",
    "def make_loaders(args, num_workers, pin_memory=True):\n",
    "    train_set = PathologyDataset([], None, \"train\")+train_augmented_dataset #Pathology.PathologyDataset()\n",
    "#    val_set = PathologyDataset([], get_validation_augmentation(), \"valid\")+val_augmented_dataset #Pathology.PathologyDataset()\n",
    "    test_set = PathologyDataset([], None, \"test\") #Pathology.PathologyDataset()\n",
    "\n",
    "    #train: train & validation 8:2\n",
    "    print(\"train 나누기 전:\",len(train_set), \"/ test 나누기 전:\",len(test_set))\n",
    "    # print(len(val_set))\n",
    "\n",
    "    # unlabel / label (60,006) ratio\n",
    "    # [1:9] 6003 / 54023 (43218 / 10,805)\n",
    "    # [2:8] 12005 / 48021 (38417 / 9604)\n",
    "    # [3:7] 18008 / 42018 (33614 / 8404)\n",
    "    # [4:6] 24010 / 36016 (28813 / 7203)\n",
    "    # [5:5] 30013 / 30013 (24010 / 6003)\n",
    "    # [6:4] 36016 / 24010 (19208 / 4802)\n",
    "    # [7:3] 42018 / 18008 (14406 / 3602)\n",
    "    # [8:2] 48021 / 12005 (9604 / 2401)\n",
    "    # [9:1] 54023 / 6003 (4802 / 1201)\n",
    "\n",
    "\n",
    "    \n",
    "    unlabel_dataset, label_dataset = torch.utils.data.random_split(train_set, [30003, 30003])\n",
    "    print(\"unlabel data:\",len(unlabel_dataset), \"/ label data:\",len(label_dataset))\n",
    "    \n",
    "    train_set, val_set = torch.utils.data.random_split(label_dataset, [24002, 6001])\n",
    "    print(\"label train 나눈 후:\",len(train_set), \"/ label validation 나눈 후:\",len(val_set))\n",
    "    print(\"test 나눈 후:\",len(test_set))\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=16, shuffle=True,\n",
    "        num_workers=8, pin_memory=True, drop_last=True,\n",
    "    ) #ori: batch size = 8, num_workers=4\n",
    "\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=16, shuffle=False,\n",
    "        num_workers=8, pin_memory=True, drop_last=True,\n",
    "    ) #ori: batch size = 8, num_workers=4\n",
    "\n",
    "    unlabel_loader = DataLoader(\n",
    "        unlabel_dataset, batch_size=16, shuffle=False,\n",
    "        num_workers=8, pin_memory=True, drop_last=True,\n",
    "    ) #ori: batch size = 8, num_workers=4\n",
    "\n",
    "#    test_loader = DataLoader(\n",
    "#        test_set, shuffle=False, pin_memory=True\n",
    "#    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set, shuffle=False, num_workers=10, pin_memory=True, drop_last=True,\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, unlabel_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, unlabel_loader, test_loader = \\\n",
    "    make_loaders([], num_workers=8, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a9eb30",
   "metadata": {},
   "source": [
    "### Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "#label smoothing\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        assert 0 <= self.smoothing < 1\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "def accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs = data['img']['image']\n",
    "            labels = data['label']\n",
    "            images, labels = inputs.float().to(DEVICE), labels.to(DEVICE, dtype=torch.int64)\n",
    "            outputs = model(images)\n",
    "            #outputs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)      \n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbc009",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#11\n",
    "import segmentation_models_pytorch as smp\n",
    "ENCODER = 'timm-resnest50d' #'timm-resnest50d' 'densenet201' 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = class_names\n",
    "ACTIVATION ='softmax2d'  #'identity' # 'softmax2d'\n",
    "DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "#if torch.cuda.is_available():\n",
    "#    torch.cuda.set_device(DEVICE)\n",
    "print(DEVICE)\n",
    "#ACTIVATION = 'sigmoid'could be None for logits or 'softmax2d' for multiclass segmentation\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation= ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e8558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#12\n",
    "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
    "TRAINING = True\n",
    "\n",
    "# Set num of epochs\n",
    "#update2 =70 \n",
    "iterations = 80\n",
    "\n",
    "# Set device: `cuda` or `cpu`\n",
    "\n",
    "print(\"Device : \",DEVICE)\n",
    "\n",
    "# define loss function\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "#(3, 0.4)\n",
    "criterion = LabelSmoothingLoss(3, 0.2)\n",
    "# tp, fp, fn, tn = smp.metrics.get_stats(output, target, mode='multilabel', threshold=0.5)\n",
    "\n",
    "# # define metrics\n",
    "# metrics = [\n",
    "#     smp.metrics.functional.iou_score(),\n",
    "# ]\n",
    "\n",
    "# define optimizer # 0.965 ~ 0.98\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001, betas=(0.92, 0.99)),\n",
    "])\n",
    "\n",
    "#update2 =7 or 5\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=7, eta_min=0.0001,\n",
    ")\n",
    "\n",
    "# define batch size\n",
    "#device = \"cuda:0\"\n",
    "\n",
    "# load best saved model checkpoint from previous commit (if present)\n",
    "# if os.path.exists('./Resnest_model/best_model.pth'):\n",
    "#     model = torch.load('./Resnest_model/best_model.pth', map_location=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "import time\n",
    "trainLoss = []\n",
    "valLoss = []\n",
    "#valDice = []\n",
    "start = time.time()\n",
    "\n",
    "# epoch = 5까지는 alpha=0으로 학습, 5~70까지는 alpha일정하게 크게 만들어 학습진행, 70이상은 alpha_t로 고정\n",
    "alpha = 0\n",
    "beta = 0.3 #1e-4 # 기존 연구 기반.\n",
    "alpha_t = 1e-4\n",
    "T1 = 5\n",
    "T2 = 70\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1848c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdm map calculation\n",
    "def compute_sdf(img_gt, out_shape):\n",
    "    \"\"\"\n",
    "    compute the signed distance map of binary mask\n",
    "    input: segmentation, shape = (batch_size, c, x, y)\n",
    "    output: the Signed Distance Map (SDM) \n",
    "    sdf(x) = 0; x in segmentation boundary\n",
    "             -inf|x-y|; x in segmentation\n",
    "             +inf|x-y|; x out of segmentation\n",
    "    normalize sdf to [-1,1]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    img_gt = img_gt.astype(np.uint8)\n",
    "    normalized_sdf = np.zeros(out_shape)\n",
    "    # thresh = 15\n",
    "\n",
    "    for b in range(out_shape[0]):  # batch size\n",
    "    # Foreground mask: cls1 or cls2\n",
    "        posmask = np.isin(img_gt[b], [1, 2]).astype(bool)  # cls1과 cls2를 foreground로 설정\n",
    "        # posmask = np.isin(img_gt[b], [1]).astype(bool)\n",
    "        if posmask.any():\n",
    "        \n",
    "            negmask = ~posmask\n",
    "            posdis = distance(posmask)\n",
    "            negdis = distance(negmask)\n",
    "            # Apply distance function and log scaling\n",
    "            # posdis = np.log1p(distance(posmask))  # Log transformation to compress range\n",
    "            # negdis = np.log1p(distance(negmask))  # Log transformation for background\n",
    "            \n",
    "            boundary = skimage_seg.find_boundaries(posmask, mode='inner').astype(np.uint8)\n",
    "            # print(f\"min negdis: {np.min(negdis)}, max negdis: {np.max(negdis)}, min posdis: {np.min(posdis)}, max posdis: {np.max(posdis)}\")\n",
    "            # Signed Distance Map 계산\n",
    "            max_posdis = np.max(posdis)\n",
    "            max_negdis = np.max(negdis)\n",
    "            if max_posdis == 0 or max_negdis == 0:\n",
    "                sdf = np.zeros_like(posdis)\n",
    "            else:\n",
    "                sdf = (negdis - np.min(negdis)) / (np.max(negdis) - np.min(negdis)) - (posdis - np.min(posdis)) / (np.max(posdis) - np.min(posdis))\n",
    "                sdf[boundary == 1] = 0\n",
    "            # print(f\"max sdf: {np.max(sdf)}, min sdf: {np.min(sdf)}\")\n",
    "            normalized_sdf[b] = sdf  # batch 내에서 전체 foreground에 대한 SDM 저장\n",
    "\n",
    "\n",
    "    return normalized_sdf\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d593c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13-2 wandb init\n",
    "import wandb\n",
    "current_time = time.strftime(\"%m-%d %H-%M\", time.localtime())\n",
    "rate = \"resnest-5:5-without_sdm\"\n",
    "wandb.init(project='sdm_pseudo', \n",
    "           name=current_time+rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c55b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#14\n",
    "torch.backends.cudnn.benchmark = False\n",
    "for epoch in range(iterations):\n",
    "    print(epoch,\"epoch start !\")\n",
    "    best_score=999999\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0\n",
    "    train_i_number = 0\n",
    "    val_i_number = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    best_acc = 0\n",
    "    model.train() # For training\n",
    "    print(\"train_loader\", len(train_loader))\n",
    "    print(\"unlabel_loader\", len(unlabel_loader))\n",
    "    for traindata, pseudodata in zip(train_loader, unlabel_loader):\n",
    "    # for data in tqdm.notebook.tqdm(train_loader):\n",
    "        #print(f\"train data {i+1}/{len(train_loader)}\")\n",
    "        #print(\"*\")\n",
    "        train_inputs = traindata['img']['image']\n",
    "        train_labels = traindata['label']\n",
    "\n",
    "        pseudo_inputs = pseudodata['img']['image']\n",
    "        pseudo_labels = pseudodata['label']\n",
    "        #print(\"train_label : \", type(train_inputs), \"pseudo label : \", type(pseudo_inputs))\n",
    "        \n",
    "        train_inputs, train_labels = train_inputs.float().to(DEVICE), train_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "        pseudo_inputs, pseudo_labels = pseudo_inputs.float().to(DEVICE), pseudo_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "        #print(\"**\") \n",
    "        \n",
    "        \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()  \n",
    "        # Feed-forward input data through the network\n",
    "        #print(\"***\")\n",
    "        pred = model(train_inputs)\n",
    "        train_outputs = F.softmax(pred, dim=1)\n",
    "        print(f\"pred: {pred[0]}\")\n",
    "        print(f\"target shape: {train_labels[0]}\")\n",
    "        #print(\"pred:\", pred)\n",
    "\n",
    "        # sdm loss\n",
    "        #pred = torch.log(train_outputs)\n",
    "        #pred = pred - pred.mean()\n",
    "        pred_sdm = torch.tanh(pred)\n",
    "        # pred_sdm = torch.sigmoid(-1500*pred_tanh)\n",
    "        # label_sdm = F.softmax(pred, dim=1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            label_sdm = compute_sdf(train_labels.cpu().numpy(), pred_sdm.shape)\n",
    "            label_sdm = torch.from_numpy(label_sdm).float().to(device=DEVICE)\n",
    "        sdm_loss = F.l2_loss(pred_sdm, label_sdm) #l1_loss(pred_tanh, pred_sdm) #mse_loss()\n",
    "        # print(\"pred_tanh:\", pred_tanh, \"pred_sdm:\", pred_sdm, \"train output:\", train_outputs)\n",
    "        #print(\"*****\")\n",
    "\n",
    "        #print(\"**\")\n",
    "        if alpha > 0: # alpha>0이면 pseudo label 포함해서 loss 계산\n",
    "            pseudo_pred = model(pseudo_inputs)\n",
    "            pseudo_outputs = F.softmax(pseudo_pred, dim=1)\n",
    "            _, pseudo_labels = torch.max(pseudo_outputs.detach(), 1)\n",
    "\n",
    "            # sdm loss 연산\n",
    "            # pseudo_pred = torch.log(pseudo_outputs)\n",
    "            # pseudo_pred = pseudo_pred - pseudo_pred.mean()   \n",
    "            pseudo_sdm = torch.tanh(pseudo_pred)\n",
    "            # pseudo_tanh = torch.sigmoid(-1500*pseudo_tanh)\n",
    "            # pseudo_label_sdm = F.softmax(pseudo_pred, dim=1)\n",
    "            with torch.no_grad():\n",
    "                pseudo_label_sdm = compute_sdf(pseudo_labels.cpu().numpy(), pseudo_sdm.shape)\n",
    "                pseudo_label_sdm = torch.from_numpy(pseudo_label_sdm).float().to(device=DEVICE)\n",
    "            pseudo_sdm_loss = F.l2_loss(pseudo_sdm, pseudo_label_sdm) #l1_loss(pseudo_tanh, pseudo_sdm) #mse_loss\n",
    "            loss = criterion(train_outputs, train_labels)  + alpha*criterion(pseudo_outputs, pseudo_labels) + beta*(sdm_loss+pseudo_sdm_loss)\n",
    "            #print(\"sdm loss: %.2f, pseudo sdm loss: %.2f, sdm included loss: %.2f\" %(sdm_loss, pseudo_sdm_loss, loss))\n",
    "            #print(\"******\")\n",
    "        else:\n",
    "            loss = criterion(train_outputs, train_labels) + beta*sdm_loss\n",
    "            #print(\"sdm loss: %.2f, sdm included loss: %.2f \"%(sdm_loss, loss))\n",
    "            # print(\"loss: \", loss)\n",
    "            #print(\"******\") \n",
    "            \n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(\"****\")\n",
    "\n",
    "        _, predicted = torch.max(train_outputs.detach(), 1)\n",
    "        total += train_labels.size(0)\n",
    "        correct += (predicted == train_labels).sum().item()\n",
    "\n",
    "        #print(\"*****\")\n",
    "    \n",
    "        if (epoch > T1) and (epoch < T2):  #epoch이 5부터 70까지일 때 \n",
    "            alpha = alpha_t*(epoch - T1)/(T2 - T1)               \n",
    "            #print(\"******\")\n",
    "\n",
    "        elif epoch >= T2:    #epoch이 70이상일 때 \n",
    "            alpha = alpha_t\n",
    "            #print(\"******\")\n",
    "    val_acc = accuracy(val_loader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './model/resnest_pseudo5.pth')    \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "        wandb.log({\"train acc\": 100*correct/total, \"validation acc\":val_acc})\n",
    "        print(\"*******\")\n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))\n",
    "        wandb.log({\"train acc\": 100*correct/total, \"validation acc\":val_acc})\n",
    "\n",
    "        print(\"*******\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a346f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14-1: without sdm\n",
    "torch.backends.cudnn.benchmark = False\n",
    "for epoch in range(iterations):\n",
    "    print(epoch,\"epoch start !\")\n",
    "    best_score=999999\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0\n",
    "    train_i_number = 0\n",
    "    val_i_number = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    best_acc = 0\n",
    "    model.train() # For training\n",
    "    #print(\"train_loader\", len(train_loader))\n",
    "    #print(\"unlabel_loader\", len(unlabel_loader))\n",
    "    for traindata, pseudodata in zip(train_loader, unlabel_loader):\n",
    "    # for data in tqdm.notebook.tqdm(train_loader):\n",
    "        #print(\"*\")\n",
    "        train_inputs = traindata['img']['image']\n",
    "        train_labels = traindata['label']\n",
    "\n",
    "        pseudo_inputs = pseudodata['img']['image']\n",
    "        pseudo_labels = pseudodata['label']\n",
    "        #print(\"train_label : \", type(train_inputs), \"pseudo label : \", type(pseudo_inputs))\n",
    "        \n",
    "        train_inputs, train_labels = train_inputs.float().to(DEVICE), train_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "        pseudo_inputs, pseudo_labels = pseudo_inputs.float().to(DEVICE), pseudo_labels.to(device=DEVICE, dtype=torch.int64) \n",
    "        #print(\"**\")\n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()  \n",
    "        # Feed-forward input data through the network\n",
    "        \n",
    "        train_outputs = model(train_inputs)\n",
    "        \n",
    "        #print(\"***\")\n",
    "        if alpha > 0: \n",
    "            pseudo_outputs = model(pseudo_inputs)\n",
    "            _, pseudo_labels = torch.max(pseudo_outputs.detach(), 1)     \n",
    "            loss = criterion(train_outputs, train_labels)  + alpha*criterion(pseudo_outputs, pseudo_labels)\n",
    "            #print(\"****\")\n",
    "        else:\n",
    "            loss = criterion(train_outputs, train_labels)\n",
    "            #print(\"****\")     \n",
    "            \n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(\"*****\")\n",
    "\n",
    "        _, predicted = torch.max(train_outputs.detach(), 1)\n",
    "        total += train_labels.size(0)\n",
    "        correct += (predicted == train_labels).sum().item()\n",
    "\n",
    "        #print(\"******\")\n",
    "    \n",
    "        if (epoch > T1) and (epoch < T2): \n",
    "            alpha = alpha_t*(epoch - T1)/(T2 - T1)               \n",
    "            #print(\"*******\")\n",
    "\n",
    "        elif epoch >= T2:  \n",
    "            alpha = alpha_t\n",
    "            #print(\"*******\")\n",
    "    print(\"********\")    \n",
    "    val_acc = accuracy(val_loader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './[SDM]pseudo_segmentation_model/resnest_pseudo5_withoutsdm.pth')    \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "        #wandb.log({\"train acc\": 100*correct/total, \"validation acc\":val_acc})\n",
    "        print(\"********\")\n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))\n",
    "        #wandb.log({\"train acc\": 100*correct/total, \"validation acc\":val_acc})\n",
    "        print(\"********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b84ba6",
   "metadata": {},
   "source": [
    "### visualize result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b285b44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "micro_iou_score_list = []\n",
    "micro_f1_score_list = []\n",
    "micro_accuracy_list = []\n",
    "micro_recall_list = []\n",
    "micro_precision_list = []\n",
    "micro_sensitivity_list = []\n",
    "micro_specificity_list = []\n",
    "\n",
    "macro_iou_score_list = []\n",
    "macro_f1_score_list = []\n",
    "macro_accuracy_list = []\n",
    "macro_recall_list = []\n",
    "macro_precision_list = []\n",
    "macro_sensitivity_list = []\n",
    "macro_specificity_list = []\n",
    "\n",
    "micro_imagewise_iou_score_list = []\n",
    "micro_imagewise_f1_score_list = []\n",
    "micro_imagewise_accuracy_list = []\n",
    "micro_imagewise_recall_list = []\n",
    "micro_imagewise_precision_list = []\n",
    "micro_imagewise_sensitivity_list = []\n",
    "micro_imagewise_specificity_list = []\n",
    "\n",
    "macro_imagewise_iou_score_list = []\n",
    "macro_imagewise_f1_score_list = []\n",
    "macro_imagewise_accuracy_list = []\n",
    "macro_imagewise_recall_list = []\n",
    "macro_imagewise_precision_list = []\n",
    "macro_imagewise_sensitivity_list = []\n",
    "macro_imagewise_specificity_list = []\n",
    "\n",
    "best_model=model\n",
    "n=0\n",
    "best_model.load_state_dict(torch.load('./model/resnest_sdm.pth', map_location=DEVICE))\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행 안 함\n",
    "    best_model.eval()\n",
    "    total=len(test_loader)\n",
    "    for i, data in enumerate(itertools.islice(test_loader, total-1)):\n",
    "    # for i, data in enumerate(test_loader):\n",
    "    # for data in tqdm.notebook.tqdm(test_loader):\n",
    "        inputs = data['img']['image']\n",
    "        # print(f\"{i}: {inputs.shape}\")\n",
    "        #print(inputs)\n",
    "        labels = data['label'] \n",
    "\n",
    "        inputs, labels = inputs.float().to(DEVICE), labels.float().to(device=DEVICE, dtype=torch.int64) #inputs.float().to(DEVICE), labels.float().to(device=DEVICE, dtype=torch.int64)    \n",
    "        preds = best_model(inputs)    \n",
    "        output = F.softmax(preds, dim=1)\n",
    " \n",
    "        target = labels\n",
    "\n",
    "\n",
    "        _, output = torch.max(output, 1)\n",
    "\n",
    "        tp, fp, fn, tn = smp.metrics.get_stats(output, target, mode='multilabel', threshold=0.5)        \n",
    "        \n",
    "        # then compute metrics with required reduction (see metric docs)\n",
    "        # micro, macro, weighted,\n",
    "        \n",
    "        micro_iou_score = round(smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_f1_score = round(smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_accuracy = round(smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"micro\").item(),3)\n",
    "        micro_recall = round(smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_precision = round(smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_sensitivity = round(smp.metrics.sensitivity(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "        micro_specificity = round(smp.metrics.specificity(tp, fp, fn, tn, reduction=\"micro\").item(), 3)\n",
    "\n",
    "        macro_iou_score = round(smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro\").item(), 3)\n",
    "        macro_f1_score = round(smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"macro\").item(), 3)\n",
    "        macro_accuracy = round(smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro\").item(),3)\n",
    "        macro_recall = round(smp.metrics.recall(tp, fp, fn, tn, reduction=\"macro\").item(), 3)\n",
    "        macro_precision = round(smp.metrics.precision(tp, fp, fn, tn, reduction=\"macro\").item(), 3)\n",
    "        macro_sensitivity = round(smp.metrics.sensitivity(tp, fp, fn, tn, reduction=\"macro\").item(), 3)\n",
    "        macro_specificity = round(smp.metrics.specificity(tp, fp, fn, tn, reduction=\"macro\").item(), 3)\n",
    "\n",
    "        micro_imagewise_iou_score = round(smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(), 3)\n",
    "        micro_imagewise_f1_score = round(smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(), 3)\n",
    "        micro_imagewise_accuracy = round(smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(),3)\n",
    "        micro_imagewise_recall = round(smp.metrics.recall(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(), 3)\n",
    "        micro_imagewise_precision = round(smp.metrics.precision(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(), 3)\n",
    "        micro_imagewise_sensitivity = round(smp.metrics.sensitivity(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(), 3)\n",
    "        micro_imagewise_specificity = round(smp.metrics.specificity(tp, fp, fn, tn, reduction=\"micro-imagewise\").item(), 3)\n",
    "\n",
    "        macro_imagewise_iou_score = round(smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(), 3)\n",
    "        macro_imagewise_f1_score = round(smp.metrics.f1_score(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(), 3)\n",
    "        macro_imagewise_accuracy = round(smp.metrics.accuracy(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(),3)\n",
    "        macro_imagewise_recall = round(smp.metrics.recall(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(), 3)\n",
    "        macro_imagewise_precision = round(smp.metrics.precision(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(), 3)\n",
    "        macro_imagewise_sensitivity = round(smp.metrics.sensitivity(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(), 3)\n",
    "        macro_imagewise_specificity = round(smp.metrics.specificity(tp, fp, fn, tn, reduction=\"macro-imagewise\").item(), 3)\n",
    "\n",
    "\n",
    "        micro_iou_score_list.append(micro_iou_score)\n",
    "        micro_f1_score_list.append(micro_f1_score)\n",
    "        micro_accuracy_list.append(micro_accuracy)\n",
    "        micro_recall_list.append(micro_recall)\n",
    "        micro_precision_list.append(micro_precision)\n",
    "        micro_sensitivity_list.append(micro_sensitivity)\n",
    "        micro_specificity_list.append(micro_specificity)\n",
    "\n",
    "        macro_iou_score_list.append(macro_iou_score)\n",
    "        macro_f1_score_list.append(macro_f1_score)\n",
    "        macro_accuracy_list.append(macro_accuracy)\n",
    "        macro_recall_list.append(macro_recall)\n",
    "        macro_precision_list.append(macro_precision)\n",
    "        macro_sensitivity_list.append(macro_sensitivity)\n",
    "        macro_specificity_list.append(macro_specificity)\n",
    "\n",
    "        micro_imagewise_iou_score_list.append(micro_imagewise_iou_score)\n",
    "        micro_imagewise_f1_score_list.append(micro_imagewise_f1_score)\n",
    "        micro_imagewise_accuracy_list.append(micro_imagewise_accuracy)\n",
    "        micro_imagewise_recall_list.append(micro_imagewise_recall)\n",
    "        micro_imagewise_precision_list.append(micro_imagewise_precision)\n",
    "        micro_imagewise_sensitivity_list.append(micro_imagewise_sensitivity)\n",
    "        micro_imagewise_specificity_list.append(micro_imagewise_specificity)\n",
    "\n",
    "        macro_imagewise_iou_score_list.append(macro_imagewise_iou_score)\n",
    "        macro_imagewise_f1_score_list.append( macro_imagewise_f1_score)\n",
    "        macro_imagewise_accuracy_list.append(macro_imagewise_accuracy)\n",
    "        macro_imagewise_recall_list.append(macro_imagewise_recall)\n",
    "        macro_imagewise_precision_list.append(macro_imagewise_precision)\n",
    "        macro_imagewise_sensitivity_list.append(macro_imagewise_sensitivity)\n",
    "        macro_imagewise_specificity_list.append(macro_imagewise_specificity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dec83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.title('micro_iou_score')\n",
    "plt.plot(micro_iou_score_list,'r-',label='IoU_score')\n",
    "plt.grid(color = 'gray', linestyle = ':', linewidth = 0.5)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.title('micro_f1_score')\n",
    "plt.plot(micro_f1_score_list,'b-',label='f1_score')\n",
    "plt.grid(color = 'gray', linestyle = ':', linewidth = 0.5)\n",
    "\n",
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.title('micro_accuracy')\n",
    "plt.plot(micro_accuracy_list,'y-',label='accuracy')\n",
    "plt.grid(color = 'gray', linestyle = ':', linewidth = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ffa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def metrics_average(metrics_list):\n",
    "    metric_avg = sum([x for x in metrics_list if isinstance(x, (int, float)) and not math.isnan(x)])/len(metrics_list)\n",
    "    return round(metric_avg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"micro_iou_score: \",metrics_average(micro_iou_score_list))\n",
    "print(\"micro_f1_score_score: \",metrics_average(micro_f1_score_list))\n",
    "print(\"micro_accuracy_score: \",metrics_average(micro_accuracy_list))\n",
    "print(\"micro_recall_score: \",metrics_average(micro_recall_list))\n",
    "print(\"micro_precision_score: \",metrics_average(micro_precision_list))\n",
    "print(\"micro_sensitivity_score: \",metrics_average(micro_sensitivity_list))\n",
    "print(\"micro_specificity_score: \",metrics_average(micro_specificity_list))\n",
    "\n",
    "# print(\"macro_iou_score: \",metrics_average(macro_iou_score_list))\n",
    "# print(\"macro_f1_score_score: \",metrics_average(macro_f1_score_list))\n",
    "# print(\"macro_accuracy_score: \",metrics_average(macro_accuracy_list))\n",
    "# print(\"macro_recall_score: \",metrics_average(macro_recall_list))\n",
    "# print(\"macro_precision_score: \",metrics_average(macro_precision_list))\n",
    "# print(\"macro_sensitivity_score: \",metrics_average(macro_sensitivity_list))\n",
    "# print(\"macro_specificity_score: \",metrics_average(macro_specificity_list))\n",
    "\n",
    "# print(\"micro_imagewise_iou_score: \",metrics_average(micro_imagewise_iou_score_list))\n",
    "# print(\"micro_imagewise_f1_score_score: \",metrics_average(micro_imagewise_f1_score_list))\n",
    "# print(\"micro_imagewise_accuracy_score: \",metrics_average(micro_imagewise_accuracy_list))\n",
    "# print(\"micro_imagewise_recall_score: \",metrics_average(micro_imagewise_recall_list))\n",
    "# print(\"micro_imagewise_precision_score: \",metrics_average(micro_imagewise_precision_list))\n",
    "# print(\"micro_imagewise_sensitivity_score: \",metrics_average(micro_imagewise_sensitivity_list))\n",
    "# print(\"micro_imagewise_specificity_score: \",metrics_average(micro_imagewise_specificity_list))\n",
    "\n",
    "# print(\"macro_imagewise_iou_score: \",metrics_average(macro_imagewise_iou_score_list))\n",
    "# print(\"macro_imagewise_f1_score_score: \",metrics_average(macro_imagewise_f1_score_list))\n",
    "# print(\"macro_imagewise_accuracy_score: \",metrics_average(macro_imagewise_accuracy_list))\n",
    "# print(\"macro_imagewise_recall_score: \",metrics_average(macro_imagewise_recall_list))\n",
    "# print(\"macro_imagewise_precision_score: \",metrics_average(macro_imagewise_precision_list))\n",
    "# print(\"macro_imagewise_sensitivity_score: \",metrics_average(macro_imagewise_sensitivity_list))\n",
    "# print(\"macro_imagewise_specificity_score: \",metrics_average(macro_imagewise_specificity_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552bf76",
   "metadata": {},
   "source": [
    "### 시각화 코드(input, target, prediction, sdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2dc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6df128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# malignant category 선언\n",
    "sem_classes = ['background', 'benign', 'malignant']\n",
    "sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(sem_classes)} \n",
    "benign_category = sem_class_to_idx[\"benign\"]\n",
    "malignant_category = sem_class_to_idx[\"malignant\"]\n",
    "\n",
    "#x,y존재\n",
    "best_model = model\n",
    "best_model.load_state_dict(torch.load('/home/SDMSegmentationCode/model/resnest_pseudo5.pth', map_location=DEVICE))\n",
    "def visualize_one_sample(test_x_data, test_y_data, model):\n",
    "\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "\n",
    "        X = test_x_data.float().to(DEVICE)\n",
    "        Y = test_y_data.float().to(DEVICE)\n",
    "        prediction = model(X)  # 예: output shape=(B, num_classes, H, W)\n",
    "        \n",
    "\n",
    "        _, pred_mask = torch.max(prediction, 1)  # shape=(B, H, W)\n",
    "        pred_mask = pred_mask[0].cpu().numpy()\n",
    "        target_mask = Y[0].cpu().numpy().squeeze()\n",
    "\n",
    "        input_img = X[0].cpu().numpy()\n",
    "        if input_img.ndim == 3 and input_img.shape[0] in [1, 3]:\n",
    "            if input_img.shape[0] == 1:\n",
    "                input_img = input_img.squeeze(0)\n",
    "                cmap_input = 'viridis'  # 단일 채널은 viridis 컬러맵 적용\n",
    "            else:\n",
    "                input_img = np.transpose(input_img, (1, 2, 0))\n",
    "                cmap_input = None  \n",
    "        else:\n",
    "            cmap_input = 'viridis'\n",
    "  \n",
    "        binary_mask = (pred_mask == benign_category).astype(np.uint8)\n",
    "    \n",
    "        sdm = compute_sdf(binary_mask, binary_mask.shape).squeeze()\n",
    "        sdm = torch.from_numpy(sdm).float()\n",
    "        \n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    axs[0].imshow(input_img, cmap=cmap_input)\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[0].axis(\"off\")\n",
    "    \n",
    "\n",
    "    axs[1].imshow(target_mask[0], cmap='viridis') # bianry_mask\n",
    "    axs[1].set_title(\"Target\")\n",
    "    axs[1].axis(\"off\")\n",
    "    \n",
    "    axs[2].imshow(binary_mask, cmap='viridis')\n",
    "    axs[2].set_title(\"Prediction\")\n",
    "    axs[2].axis(\"off\")\n",
    "    \n",
    "    im = axs[3].imshow(sdm, cmap='seismic')\n",
    "    axs[3].set_title(\"SDM Output\")\n",
    "    axs[3].axis(\"off\")\n",
    "    fig.colorbar(im, ax=axs[3], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6df128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n",
    "test_x_data_path = '/home/SDMSegmentationCode/PathologyDataset/labelled/test/png'\n",
    "test_y_data_path = '/home/DMSegmentationCode/PathologyDataset/labelled/test/png_label'\n",
    "\n",
    "test_x_data = sorted(os.listdir(test_x_data_path))\n",
    "test_y_data = sorted(os.listdir(test_y_data_path))\n",
    "\n",
    "for i in range(50, 52):\n",
    "\n",
    "   xname = test_x_data[i]\n",
    "   yname = test_y_data[i]\n",
    "\n",
    "   x_path = os.path.join(test_x_data_path, xname)\n",
    "   y_path = os.path.join(test_y_data_path, yname)\n",
    "    \n",
    "    \n",
    "   x = cv2.imread(x_path)\n",
    "   x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(x)\n",
    "   X = torch.Tensor(x)\n",
    "   X = X /255\n",
    "    \n",
    "    # print(X)\n",
    "     \n",
    "   y = cv2.imread(y_path)    \n",
    "   y = cv2.cvtColor(y, cv2.COLOR_BGR2RGB)\n",
    "    # plt.imshow(y)\n",
    "   Y = torch.Tensor(y)\n",
    "    # print(Y)\n",
    "    \n",
    "    #y = cv2.imread(yname)\n",
    "    #y = cv2.cvtColor(cv2.imread(yname), cv2.COLOR_BGR2RGB)\n",
    "    #Y = TF.to_tensor(y)\n",
    "    \n",
    "    #파일명 출력\n",
    "   print(\"x 파일명 : \",xname)\n",
    "   print(\"y 파일명 : \",yname)\n",
    "\n",
    "    \n",
    "   X = np.transpose(X, (2, 0, 1))\n",
    "   Y = np.transpose(Y, (2, 0, 1))\n",
    "    \n",
    "   X.unsqueeze_(0)\n",
    "   Y.unsqueeze_(0)\n",
    "    \n",
    "   #데이터 shape 출력\n",
    "   # print(\"기본 x shape : \",X.shape)\n",
    "   # print(\"기본 y shape : \",X.shape)\n",
    "   # \n",
    "    \n",
    "   # 시각화: 한 행에 2개의 이미지 (좌측: x, 우측: y)\n",
    "   # plt.subplot(1, 2, 1)\n",
    "   # plt.imshow(x)\n",
    "   # plt.title(\"X Image\")\n",
    "\n",
    "   # plt.subplot(1, 2, 2)\n",
    "   # plt.imshow(y)\n",
    "   # plt.title(\"Y Mask\")\n",
    "\n",
    "   # plt.show()\n",
    "\n",
    "   visualize_one_sample(X, Y, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1df60",
   "metadata": {},
   "source": [
    "#### visualize sdm(single image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_image = '/home/SegmentationCode/PathologyDataset/labelled/test/png_label/S21-3099_x100_11_[1088_1088].png'\n",
    "\n",
    "label = cv2.imread(label_image)\n",
    "label = np.transpose(label, (2, 0, 1))\n",
    "label = label/255\n",
    "\n",
    "sdm = compute_sdf(label[2], label[2].shape)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# 원본 라벨 이미지 시각화\n",
    "axs[0].imshow(label[2], cmap='viridis')\n",
    "axs[0].set_title('Label Image')\n",
    "\n",
    "im = axs[1].imshow(sdm, cmap='seismic', vmin=-1, vmax=1)\n",
    "axs[1].set_title('Signed Distance Map')\n",
    "\n",
    "fig.colorbar(im, ax=axs[1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a935bc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "both_images = np.hstack((inputs[1].permute(1,2,0).cpu().detach().numpy(), np.repeat(malignant_mask_uint8[:, :, None], 3, axis=-1)))\n",
    "Image.fromarray(both_images.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [SemanticSegmentationTarget(1, malignant_mask_float)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a2582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae60111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inputs[4].permute(1,2,0).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5efe5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(output[1].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = inputs[1].permute(1,2,0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs[1].permute(1,2,0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38370528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with GradCAM(model=model,\n",
    "             target_layers=target_layers,\n",
    "             use_cuda=torch.cuda.is_available()) as cam:\n",
    "    grayscale_cam = cam(input_tensor=inputs,\n",
    "                        targets=targets)[0, :]\n",
    "    cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "Image.fromarray(cam_image)\n",
    "\n",
    "#원본이미지 같이 출력이 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grayscale_cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_cam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b53d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79016474",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.argmax(preds[4].cpu().detach().numpy(), axis=0), vmin = 0, vmax =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its ground truth. \n",
    "def dice_coef(y_pred,y_true,smooth=1):\n",
    "    #_, prediction = torch.max(y_pred, 1)\n",
    "    y_pred = y_pred.view(batch_size,-1)\n",
    "    y_true = y_true.view(batch_size,-1)\n",
    "    y_pred = (y_pred > 0.5).float()\n",
    "    y_true = (y_true > 0.5).float()\n",
    "    dice = (2* torch.sum(y_pred*y_true)+smooth)/(torch.sum(y_pred)+torch.sum(y_true)+smooth)\n",
    "    dice = torch.mean(dice , axis=0)\n",
    "    return dice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
