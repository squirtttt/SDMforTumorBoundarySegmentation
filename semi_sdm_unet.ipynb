{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fdfee7e2",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129070b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1\n",
    "import os\n",
    "import sys\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as album\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "#from dataloaders.datasets import Pathology\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# sdm\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "from skimage import segmentation as skimage_seg\n",
    "from skimage import morphology\n",
    "\n",
    "# test loader\n",
    "import itertools\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "\n",
    "import math\n",
    "\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "class Path(object):\n",
    "    @staticmethod\n",
    "    def pathology_root_dir():\n",
    "        root_dir = \"\"\n",
    "        return os.path.join(root_dir, \"BCSS_patch\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e6818d3",
   "metadata": {},
   "source": [
    "### data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee8fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "#helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"\n",
    "    Plot images in one row\n",
    "    \"\"\"\n",
    "    n_images = len(images)\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for idx, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n_images, idx + 1)\n",
    "        plt.xticks([]); \n",
    "        plt.yticks([])\n",
    "        # get title from the parameter names\n",
    "        plt.title(name.replace('_',' ').title(), fontsize=20)\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "# Perform one hot encoding on label\n",
    "def one_hot_encode(label, label_values):\n",
    "    semantic_map = []\n",
    "    for colour in label_values:\n",
    "        equality = np.equal(label, colour)\n",
    "        class_map = np.all(equality, axis = -1)\n",
    "        semantic_map.append(class_map)\n",
    "    semantic_map = np.stack(semantic_map, axis=-1)\n",
    "\n",
    "    return semantic_map\n",
    "    \n",
    "# Perform reverse one-hot-encoding on labels / preds\n",
    "def reverse_one_hot(image):\n",
    "    x = np.argmax(image, axis = -1)\n",
    "    return x\n",
    "\n",
    "# Perform colour coding on the reverse-one-hot outputs\n",
    "def colour_code_segmentation(image, label_values):\n",
    "    colour_codes = np.array(label_values)\n",
    "    x = colour_codes[image.astype(int)]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ef28dd9",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "# Useful to shortlist specific classes in datasets with large number of classes\n",
    "class_names = ['background', 'tumor ', 'stroma', 'dcis']\n",
    "select_classes = ['background', 'tumor ', 'stroma', 'dcis']\n",
    "\n",
    "background=[[0, 0, 0],]\n",
    "\n",
    "# Get RGB values of required classes\n",
    "class_rgb_values = [[0, 0, 0], [255, 0, 0], [0, 255, 0], [0, 0, 255]]\n",
    "\n",
    "select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
    "select_class_rgb_values =  np.array(class_rgb_values)[select_class_indices]\n",
    "\n",
    "print('Selected classes and their corresponding RGB values in labels:')\n",
    "print('Class Names: ', class_names)\n",
    "print('Class RGB values: ', class_rgb_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e999a997",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def get_training_augmentation():\n",
    "    train_transform = [    \n",
    "        #album.RandomCrop(height=256, width=256, always_apply=True),\n",
    "        album.OneOf(\n",
    "            [\n",
    "                album.HorizontalFlip(p=1),\n",
    "                album.VerticalFlip(p=1),\n",
    "                album.RandomRotate90(p=1),\n",
    "            ],\n",
    "            p=1,\n",
    "        ),\n",
    "    ]\n",
    "    return album.Compose(train_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn=None):\n",
    "    _transform = []\n",
    "    if preprocessing_fn:\n",
    "        _transform.append(album.Lambda(image=preprocessing_fn))\n",
    "    _transform.append(album.Lambda(image=to_tensor, mask=to_tensor))\n",
    "        \n",
    "    return album.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5612797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, args, augmentation, split:str, img_list=None,  fraction: float=1.0, seed: int=42):\n",
    "        self.augmentation = augmentation\n",
    "        self.args = args\n",
    "        self.data_dir = os.path.join(Path.pathology_root_dir(), 'labelled', split, 'png')\n",
    "\n",
    "        if img_list is not None:\n",
    "            self.imgs = img_list\n",
    "            \n",
    "        else:\n",
    "            all_imgs = sorted([os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir)])\n",
    "            if fraction <= 1.0:\n",
    "                np.random.seed(seed)\n",
    "                selected_indices = np.random.choice(len(all_imgs), int(len(all_imgs)*fraction), replace=False)\n",
    "                self.imgs = [all_imgs[i] for i in sorted(selected_indices)]\n",
    "            else: \n",
    "                self.imgs = all_imgs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _img = cv2.cvtColor(cv2.imread(self.imgs[index]), cv2.COLOR_BGR2RGB)\n",
    "        mask_path = self.imgs[index].replace(\"png\", \"npy\")\n",
    "        _label = np.load(mask_path, allow_pickle=True).item().get('label')\n",
    "\n",
    "        if self.augmentation != None:\n",
    "            sample = self.augmentation(image=_img, mask=_label)\n",
    "            _img, _label = sample['image'], sample['mask']\n",
    "        \n",
    "        _img = _img/255\n",
    "        transform = A.Compose([ToTensorV2()])\n",
    "        _img = transform(image=_img)\n",
    "        _label = torch.as_tensor(_label).long()\n",
    "\n",
    "        sample = {\n",
    "            'img': _img,\n",
    "            'label':_label,\n",
    "            'path': mask_path\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518f4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_aug_dataset = LabeledDataset([], get_training_augmentation(), \"train\", None, 0.5)\n",
    "\n",
    "labeled_img_list = train_aug_dataset.imgs\n",
    "print(len(train_aug_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):   \n",
    "    batch = [b for b in batch if b is not None]\n",
    "    return torch.utils.data.dataloader.default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b2c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate unlabeled dataset\n",
    "class UnlabeledDataset(Dataset):\n",
    "    def __init__(self, args, augmentation, split: str, img_list):\n",
    "        self.augmentation = augmentation\n",
    "        self.args = args\n",
    "        self.data_dir = os.path.join(Path.pathology_root_dir(), 'labelled', split, 'png')\n",
    "\n",
    "        exclude_files = set([os.path.basename(path) for path in img_list])\n",
    "\n",
    "        all_imgs = sorted(os.listdir(self.data_dir))\n",
    "        remaining_imgs = [f for f in all_imgs if f not in exclude_files]\n",
    "\n",
    "        self.imgs = [os.path.join(self.data_dir, f) for f in remaining_imgs]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        _img = cv2.cvtColor(cv2.imread(self.imgs[index]), cv2.COLOR_BGR2RGB)\n",
    "        mask_path = self.imgs[index]\n",
    "\n",
    "        _img = _img / 255\n",
    "        transform = A.Compose([ToTensorV2()])\n",
    "        _img = transform(image=_img)\n",
    "\n",
    "        sample = {\n",
    "            'img': _img,\n",
    "            'path': mask_path\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6a960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate train_loader\n",
    "\n",
    "def labeled_make_loaders(args, num_workers, pin_memory=True):\n",
    "    train_set = LabeledDataset([], None, \"train\", labeled_img_list)+train_aug_dataset\n",
    "    test_set = LabeledDataset([], None, \"test\")\n",
    "    unlabel_set = UnlabeledDataset([], None, \"train\", labeled_img_list)\n",
    "    train_set, val_set = torch.utils.data.random_split(train_set, [7356, 1840])\n",
    "\n",
    "    print(f\"train set: {len(train_set)} | val set: {len(val_set)} | test set: {len(test_set)} | unlabel set: {len(unlabel_set)}\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set, batch_size=16, shuffle = True, \n",
    "        num_workers=8, pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size = 16, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set, shuffle=False, num_workers=10, pin_memory=True\n",
    "    )\n",
    "\n",
    "    unlabel_loader = DataLoader(\n",
    "        unlabel_set, shuffle=False, num_workers=10, pin_memory=True\n",
    "    )\n",
    "\n",
    "\n",
    "    return train_loader, val_loader, test_loader, unlabel_loader\n",
    "\n",
    "label_train_loader, label_val_loader, test_loader, unlabel_loader = labeled_make_loaders([], num_workers=8, pin_memory=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0a9eb30",
   "metadata": {},
   "source": [
    "### Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9\n",
    "#label smoothing\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        assert 0 <= self.smoothing < 1\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ff96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "def accuracy(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data in dataloader:\n",
    "            inputs = data['img']['image']\n",
    "            labels = data['label']\n",
    "            images, labels = inputs.float().to(DEVICE), labels.to(DEVICE, dtype=torch.int64)\n",
    "            outputs = model(images)\n",
    "            #outputs = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.detach(), 1)\n",
    "            total += labels.size(0)      \n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100*correct/total\n",
    "    model.train()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1729c85",
   "metadata": {},
   "source": [
    "### model configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a253e01",
   "metadata": {},
   "source": [
    "model listup\n",
    "- semi-supervised\n",
    "    - Unet\n",
    "        - encoder: resnet50\n",
    "        - encoder-weights: none\n",
    "    - Unet\n",
    "        - encoder: timm-resnest50d\n",
    "    - Deeplabv3+\n",
    "        - encoder: resnet50\n",
    "    - Segformer\n",
    "        - mitb2\n",
    "    - Unet : with sdm\n",
    "        - encoder: resnet50\n",
    "        - encoder-weights: imagenet\n",
    "        - activation: identity\n",
    "    - Unet : with sdm\n",
    "        - encoder: resnest50\n",
    "        - encoder-weights: imagenet\n",
    "        - activation: identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbc009",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#11\n",
    "import segmentation_models_pytorch as smp\n",
    "ENCODER = 'timm-resnest50d' #'timm-resnest50d' 'densenet201' 'resnet34'\n",
    "ENCODER_WEIGHTS = None\n",
    "CLASSES = class_names\n",
    "ACTIVATION ='softmax2d'  #'identity' # 'softmax2d'\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(DEVICE)\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation= ACTIVATION,\n",
    ")\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e8558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#12\n",
    "# Set flag to train the model or not. If set to 'False', only prediction is performed (using an older model checkpoint)\n",
    "TRAINING = True\n",
    "\n",
    "iterations = 80\n",
    "\n",
    "print(\"Device : \",DEVICE)\n",
    "\n",
    "criterion = LabelSmoothingLoss(3, 0.2)\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001, betas=(0.92, 0.99)),\n",
    "])\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=7, eta_min=0.0001,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13\n",
    "import time\n",
    "trainLoss = []\n",
    "valLoss = []\n",
    "#valDice = []\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "alpha = 0\n",
    "beta = 0.3\n",
    "alpha_t = 1e-4\n",
    "T1 = 5\n",
    "T2 = 70\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1848c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdm map calculation\n",
    "def compute_sdf(img_gt, out_shape):\n",
    "\n",
    "    img_gt = img_gt.astype(np.uint8)\n",
    "    normalized_sdf = np.zeros(out_shape)\n",
    "    # thresh = 15\n",
    "\n",
    "    for b in range(out_shape[0]):  # batch size\n",
    "    # Foreground mask: cls1 or cls2\n",
    "        posmask = np.isin(img_gt[b], [1, 2]).astype(bool)  # cls1과 cls2를 foreground로 설정\n",
    "        # posmask = np.isin(img_gt[b], [1]).astype(bool)\n",
    "        if posmask.any():\n",
    "        \n",
    "            negmask = ~posmask\n",
    "            posdis = distance(posmask)\n",
    "            negdis = distance(negmask)\n",
    "      \n",
    "            boundary = skimage_seg.find_boundaries(posmask, mode='inner').astype(np.uint8)\n",
    "         \n",
    "            max_posdis = np.max(posdis)\n",
    "            max_negdis = np.max(negdis)\n",
    "            if max_posdis == 0 or max_negdis == 0:\n",
    "                sdf = np.zeros_like(posdis)\n",
    "            else:\n",
    "                sdf = (negdis - np.min(negdis)) / (np.max(negdis) - np.min(negdis)) - (posdis - np.min(posdis)) / (np.max(posdis) - np.min(posdis))\n",
    "                sdf[boundary == 1] = 0\n",
    "\n",
    "            normalized_sdf[b] = sdf \n",
    "\n",
    "\n",
    "    return normalized_sdf\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446f757",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43908ecf",
   "metadata": {},
   "source": [
    "### pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ea1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14: semi-supervised learning: pre-training\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(f\"pretraining starts!!\")\n",
    "for epoch in range(pre_iterations):\n",
    "    print(f\"{epoch} iteration start!\")\n",
    "    best_score = 999999\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0\n",
    "    train_i_number = 0\n",
    "    val_i_number = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    best_acc = 0\n",
    "    model.train() # For training\n",
    "    print(f'train loader: {len(label_train_loader)}')\n",
    "    for traindata in tqdm.notebook.tqdm(label_train_loader):\n",
    "        train_inputs = traindata['img']['image']\n",
    "        train_labels = traindata['label']\n",
    "\n",
    "        train_inputs, train_labels = train_inputs.float().to(DEVICE), train_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = model(train_inputs)\n",
    "        train_outputs = F.softmax(pred, dim=1)\n",
    "\n",
    "        # compute sdm\n",
    "        pred_sdm = torch.tanh(pred)\n",
    "\n",
    "        label_sdm = torch.from_numpy(compute_sdm(train_labels)).float().to(pred_sdm.device)\n",
    "        # print(f'pred shape: {pred_sdm.shape}, label shape: {label_sdm.shape}')\n",
    "        sdm_loss = F.mse_loss(pred_sdm, label_sdm)\n",
    "    \n",
    "        # compute loss\n",
    "        loss = criterion(train_outputs, train_labels) + (beta*sdm_loss)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(train_outputs.detach(), 1)\n",
    "        total += train_labels.size(0)\n",
    "        correct += (predicted == train_labels).sum().item()\n",
    "    val_acc = accuracy(label_val_loader)\n",
    "\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './pretrained/sdm_unet_resnest50.pth')\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))\n",
    "        print(\"*******\") \n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a92cf",
   "metadata": {},
   "source": [
    "### save pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097424c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pseudo-labels\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm.notebook.tqdm(unlabel_loader):\n",
    "        unlabel_input = batch['img']['image']\n",
    "        unlabel_input = unlabel_input.float().to(DEVICE)\n",
    "        path = os.path.basename(batch['path'][0]).replace('png', 'npy')\n",
    "\n",
    "        unlabel_output = model(unlabel_input) \n",
    "        \n",
    "        unlabel_output = F.softmax(unlabel_output, dim=1)\n",
    "        _, pred_mask = torch.max(unlabel_output, 1)\n",
    "        pred_mask = pred_mask[0].cpu().numpy()\n",
    "        image_np = unlabel_input.cpu().numpy()\n",
    "\n",
    "        save_dict= {\n",
    "            'input': image_np, \n",
    "            'label': pred_mask\n",
    "        }\n",
    "\n",
    "        save_path = os.path.join(Path.pathology_root_dir(), 'pseudo', 'sdm_unet_resnest50', 'npy')\n",
    "        os.makedirs(save_path, exist_ok=True) \n",
    "        save_file = os.path.join(save_path, path)\n",
    "        np.save(save_file, save_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7e922",
   "metadata": {},
   "source": [
    "### pseudo-label dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c7d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoDataset(Dataset):\n",
    "    def __init__(self, args, augmentation, split:str, img_list):\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.args = args\n",
    "        self.img_dir = os.path.join(Path.pathology_root_dir(), 'labelled', split, 'png')\n",
    "        \n",
    "        exclude_files = set([os.path.basename(p) for p in img_list])\n",
    "\n",
    "        all_imgs = sorted(os.listdir(self.img_dir))\n",
    "\n",
    "        \n",
    "        remaining_imgs = [f for f in all_imgs if f not in exclude_files]\n",
    "\n",
    "        self.imgs = [os.path.join(self.img_dir, f) for f in remaining_imgs]\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _img = cv2.cvtColor(cv2.imread(self.imgs[index]), cv2.COLOR_BGR2RGB)\n",
    "        file_name = os.path.basename(self.imgs[index]).replace(\"png\", \"npy\")\n",
    "        label_path = os.path.join(Path.pathology_root_dir(), 'pseudo','sdm_unet_resnest50', 'npy', file_name)\n",
    "        _label = np.load(label_path, allow_pickle=True).item().get('label')\n",
    "\n",
    "        if self.augmentation != None:\n",
    "            sample = self.augmentation(image= _img, mask = _label)\n",
    "            _img, _label = sample['image'], sample['mask']\n",
    "\n",
    "        _img = _img/255\n",
    "        transform = A.Compose([ToTensorV2()])\n",
    "        _img = transform(image=_img)\n",
    "        _label = torch.as_tensor(_label).long()\n",
    "\n",
    "        sample = {\n",
    "            'img': _img,\n",
    "            'label': _label, \n",
    "            'path': label_path\n",
    "        }\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88398967",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_aug_dataset = PseudoDataset([], get_training_augmentation(), \"train\", labeled_img_list)\n",
    "\n",
    "print(len(pseudo_aug_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce541de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug_dataset = LabeledDataset([], get_training_augmentation(), \"train\", labeled_img_list, 0.5)\n",
    "\n",
    "print(len(train_aug_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1419331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeled+pseudo data loader\n",
    "def whole_make_loaders(args, num_workers, pin_memory=True):\n",
    "    pseudo_set = PseudoDataset([], None, \"train\", labeled_img_list) +pseudo_aug_dataset\n",
    "    label_set = LabeledDataset([], None, \"train\", labeled_img_list) +train_aug_dataset\n",
    "    \n",
    "\n",
    "    test_set = LabeledDataset([], None, \"test\")\n",
    "\n",
    "    total_len = len(label_set)\n",
    "    train_len = int(total_len*0.8)\n",
    "    val_len = total_len - train_len\n",
    "\n",
    "    pseudo_len = len(pseudo_set)\n",
    "    pseudo_train_len = int(pseudo_len*0.8)\n",
    "    pseudo_val_len = pseudo_len - pseudo_train_len\n",
    "\n",
    "    labeled_train_set, labeled_val_set = torch.utils.data.random_split(label_set, [train_len, val_len])\n",
    "    pseudo_train_set, pseudo_val_set = torch.utils.data.random_split(pseudo_set, [pseudo_train_len, pseudo_val_len])\n",
    "\n",
    "    val_set = pseudo_val_set + labeled_val_set\n",
    "\n",
    "    print(f'labeled train set: {len(labeled_train_set)} | pseudo train set: {len(pseudo_train_set)} | val set: {len(val_set)} | test_set: {len(test_set)}')\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        labeled_train_set, batch_size=16, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,\n",
    "    )\n",
    "\n",
    "    pseudo_train_loader = DataLoader(\n",
    "        pseudo_train_set, batch_size=16, shuffle=True,\n",
    "        num_workers=8, pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set, batch_size=16, shuffle=False,\n",
    "        num_workers=8, pin_memory=True,\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_set, shuffle=False, num_workers=10, pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    return train_loader, pseudo_train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, pseudo_train_loader, val_loader, test_loader = whole_make_loaders([], num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label+pseudo train : without sdm\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.benchmark = False\n",
    "for epoch in range(iterations):\n",
    "    print(epoch,\"epoch start !\")\n",
    "    best_score=999999\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0\n",
    "    train_i_number = 0\n",
    "    val_i_number = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    best_acc = 0\n",
    "    model.train() # For training\n",
    "    print(\"train_loader\", len(train_loader))\n",
    "    # for traindata in zip(train_loader):\n",
    "    for traindata, pseudodata in zip(train_loader, pseudo_train_loader):\n",
    "\n",
    "        train_inputs = traindata['img']['image']\n",
    "        train_labels = traindata['label']\n",
    "\n",
    "        pseudo_inputs = pseudodata['img']['image']\n",
    "        pseudo_labels = pseudodata['label']\n",
    "\n",
    "        train_inputs, train_labels = train_inputs.float().to(DEVICE), train_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "        pseudo_inputs, pseudo_labels = pseudo_inputs.float().to(DEVICE), pseudo_labels.to(device=DEVICE, dtype=torch.int64) \n",
    "        #print(\"**\") \n",
    "        \n",
    "    \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()  \n",
    "        # Feed-forward input data through the network\n",
    "        #print(\"***\")\n",
    "        train_outputs = model(train_inputs)\n",
    "\n",
    "        if alpha > 0: \n",
    "            pseudo_outputs = model(pseudo_inputs)\n",
    "            _, pseudo_labels = torch.max(pseudo_outputs.detach(), 1)     \n",
    "            loss = criterion(train_outputs, train_labels)  + alpha*criterion(pseudo_outputs, pseudo_labels)\n",
    "            #print(\"****\")\n",
    "        else:\n",
    "            loss = criterion(train_outputs, train_labels)\n",
    "\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(train_outputs.detach(), 1)\n",
    "        total += train_labels.size(0)\n",
    "        correct += (predicted == train_labels).sum().item()\n",
    "\n",
    "    val_acc = accuracy(val_loader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './[BCSS]segmentation_model/sdm_semi_unet_resnest50.pth')    \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "        \n",
    "        print(\"*******\")\n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))\n",
    "        \n",
    "        The \n",
    "\n",
    "        print(\"*******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51c55b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pseudo-label training: with SDM\n",
    "torch.backends.cudnn.benchmark = False\n",
    "for epoch in range(iterations):\n",
    "    print(epoch,\"epoch start !\")\n",
    "    best_score=999999\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0\n",
    "    train_i_number = 0\n",
    "    val_i_number = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    best_acc = 0\n",
    "    model.train() # For training\n",
    "    print(\"train_loader\", len(train_loader))\n",
    "    print(\"unlabel_loader\", len(unlabel_loader))\n",
    "    for traindata, pseudodata in zip(train_loader, unlabel_loader):\n",
    "\n",
    "        train_inputs = traindata['img']['image']\n",
    "        train_labels = traindata['label']\n",
    "\n",
    "        pseudo_inputs = pseudodata['img']['image']\n",
    "        pseudo_labels = pseudodata['label']\n",
    "\n",
    "        train_inputs, train_labels = train_inputs.float().to(DEVICE), train_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "        pseudo_inputs, pseudo_labels = pseudo_inputs.float().to(DEVICE), pseudo_labels.to(device=DEVICE, dtype=torch.int64)\n",
    "\n",
    "    \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()  \n",
    "        # Feed-forward input data through the network\n",
    "\n",
    "        pred = model(train_inputs)\n",
    "        train_outputs = F.softmax(pred, dim=1)\n",
    "        print(f\"pred: {pred[0]}\")\n",
    "        print(f\"target shape: {train_labels[0]}\")\n",
    "\n",
    "        # sdm loss\n",
    "        #pred = torch.log(train_outputs)\n",
    "        #pred = pred - pred.mean()\n",
    "        pred_sdm = torch.tanh(pred)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            label_sdm = compute_sdf(train_labels.cpu().numpy(), pred_sdm.shape)\n",
    "            label_sdm = torch.from_numpy(label_sdm).float().to(device=DEVICE)\n",
    "        sdm_loss = F.l2_loss(pred_sdm, label_sdm) #l1_loss(pred_tanh, pred_sdm) #mse_loss()\n",
    "\n",
    "        if alpha > 0:\n",
    "            pseudo_pred = model(pseudo_inputs)\n",
    "            pseudo_outputs = F.softmax(pseudo_pred, dim=1)\n",
    "            _, pseudo_labels = torch.max(pseudo_outputs.detach(), 1)\n",
    "\n",
    "  \n",
    "            pseudo_sdm = torch.tanh(pseudo_pred)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pseudo_label_sdm = compute_sdf(pseudo_labels.cpu().numpy(), pseudo_sdm.shape)\n",
    "                pseudo_label_sdm = torch.from_numpy(pseudo_label_sdm).float().to(device=DEVICE)\n",
    "            pseudo_sdm_loss = F.l2_loss(pseudo_sdm, pseudo_label_sdm) #l1_loss(pseudo_tanh, pseudo_sdm) #mse_loss\n",
    "            loss = criterion(train_outputs, train_labels)  + alpha*criterion(pseudo_outputs, pseudo_labels) + beta*(sdm_loss+pseudo_sdm_loss)\n",
    "   \n",
    "        else:\n",
    "            loss = criterion(train_outputs, train_labels) + beta*sdm_loss\n",
    "\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        #print(\"****\")\n",
    "\n",
    "        _, predicted = torch.max(train_outputs.detach(), 1)\n",
    "        total += train_labels.size(0)\n",
    "        correct += (predicted == train_labels).sum().item()\n",
    "\n",
    "        #print(\"*****\")\n",
    "    \n",
    "        if (epoch > T1) and (epoch < T2):\n",
    "            alpha = alpha_t*(epoch - T1)/(T2 - T1)               \n",
    "            #print(\"******\")\n",
    "\n",
    "        elif epoch >= T2: \n",
    "            alpha = alpha_t\n",
    "            #print(\"******\")\n",
    "    val_acc = accuracy(val_loader)\n",
    "    if val_acc >= best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), './model/resnest_pseudo5.pth')    \n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f - Saved the best model' %(epoch, 100*correct/total, val_acc))  \n",
    "        wandb.log({\"train acc\": 100*correct/total, \"validation acc\":val_acc})\n",
    "        print(\"*******\")\n",
    "    elif epoch % 10 == 0:\n",
    "        print('[%d] train acc: %.2f, validation acc: %.2f' %(epoch, 100*correct/total, val_acc))\n",
    "        wandb.log({\"train acc\": 100*correct/total, \"validation acc\":val_acc})\n",
    "\n",
    "        print(\"*******\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pseudo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
